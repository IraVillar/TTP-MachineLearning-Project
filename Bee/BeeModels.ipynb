{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Import </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "model_trainylog = pd.read_csv('cleanedtrainwithYlog.csv')\n",
    "model_test = pd.read_csv('cleanedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>ylogSalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.684507</td>\n",
       "      <td>6.831328</td>\n",
       "      <td>20.212182</td>\n",
       "      <td>3.440268</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>15.187527</td>\n",
       "      <td>15.187527</td>\n",
       "      <td>9.059126</td>\n",
       "      <td>12.170327</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.247699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.858807</td>\n",
       "      <td>7.221214</td>\n",
       "      <td>20.712205</td>\n",
       "      <td>3.259674</td>\n",
       "      <td>3.602594</td>\n",
       "      <td>15.145138</td>\n",
       "      <td>15.145138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.062832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.109016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.684507</td>\n",
       "      <td>6.914940</td>\n",
       "      <td>21.347241</td>\n",
       "      <td>3.440268</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>15.184404</td>\n",
       "      <td>15.185966</td>\n",
       "      <td>8.646538</td>\n",
       "      <td>11.200343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.317171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.968981</td>\n",
       "      <td>6.684507</td>\n",
       "      <td>20.691553</td>\n",
       "      <td>3.440268</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>15.047529</td>\n",
       "      <td>15.135652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.274266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.849405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.684507</td>\n",
       "      <td>7.314735</td>\n",
       "      <td>22.325160</td>\n",
       "      <td>3.602594</td>\n",
       "      <td>3.055642</td>\n",
       "      <td>15.182841</td>\n",
       "      <td>15.182841</td>\n",
       "      <td>10.391827</td>\n",
       "      <td>11.971129</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.429220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  MSSubClass  LotFrontage    LotArea  OverallQual  OverallCond  \\\n",
       "0           0    6.684507     6.831328  20.212182     3.440268     3.055642   \n",
       "1           1    4.858807     7.221214  20.712205     3.259674     3.602594   \n",
       "2           2    6.684507     6.914940  21.347241     3.440268     3.055642   \n",
       "3           3    6.968981     6.684507  20.691553     3.440268     3.055642   \n",
       "4           4    6.684507     7.314735  22.325160     3.602594     3.055642   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLw  \\\n",
       "0  15.187527     15.187527    9.059126   12.170327  ...               0   \n",
       "1  15.145138     15.145138    1.000000   13.062832  ...               0   \n",
       "2  15.184404     15.185966    8.646538   11.200343  ...               0   \n",
       "3  15.047529     15.135652    1.000000    9.274266  ...               0   \n",
       "4  15.182841     15.182841   10.391827   11.971129  ...               0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n",
       "0             0             0            1                      0   \n",
       "1             0             0            1                      0   \n",
       "2             0             0            1                      0   \n",
       "3             0             0            1                      0   \n",
       "4             0             0            1                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  ylogSalePrice  \n",
       "0                      0      12.247699  \n",
       "1                      0      12.109016  \n",
       "2                      0      12.317171  \n",
       "3                      0      11.849405  \n",
       "4                      0      12.429220  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainylog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train and Test Data Split </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_trainylog.drop(['ylogSalePrice'], axis = 1)\n",
    "y = model_trainylog['ylogSalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modeling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified KFold\n",
    "stratify_divide = StratifiedKFold(n_splits=10, shuffle=True, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KFold for Cross Validation\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE_CV\n",
    "def rmse_cv(model):\n",
    "    kf = KFold(n_splits = 5, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Gradient Boosting Regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "gbm.set_params(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training data\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set R^2 is: 0.96555\n",
      "The test set R^2 is is: 0.89624\n"
     ]
    }
   ],
   "source": [
    "print(\"The train set R^2 is: %.5f\" % gbm.score(X_train, y_train))\n",
    "print(\"The test set R^2 is is: %.5f\" % gbm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): $ 14720.51\n",
      "Mean Squared Error (MSE): 0.01638708223310358\n",
      "Root Mean Square Error (RMSE): 0.1280120394068604\n",
      "Mean Absolute Percent Error (MAPE): 9.11 %.\n"
     ]
    }
   ],
   "source": [
    "# Initial prediction\n",
    "gbm_pred = gbm.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(np.expm1(gbm_pred) - np.expm1(y_test))\n",
    "\n",
    "# Print out MAE, MSE, and RMSE\n",
    "print('Mean Absolute Error (MAE): $', round(np.mean(errors), 2))\n",
    "print('Mean Squared Error (MSE):', mean_squared_error(y_test, gbm_pred))\n",
    "print('Root Mean Square Error (RMSE):', np.sqrt(mean_squared_error(y_test, gbm_pred)))\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / np.expm1(y_test))\n",
    "print('Mean Absolute Percent Error (MAPE):', round(np.mean(mape), 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Tune Hyperparameters </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grids\n",
    "gbm_param_grid={'n_estimators':[300, 400, 500, 600],\n",
    "                'learning_rate':[0.05, 0.1, 1.5],\n",
    "                'max_depth':[1, 2, 3],\n",
    "                'min_samples_leaf':[1, 2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.59 s, sys: 329 ms, total: 5.92 s\n",
      "Wall time: 7min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=28, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_wei...\n",
       "                                                 presort='auto',\n",
       "                                                 random_state=42, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 1.5],\n",
       "                         'max_depth': [1, 2, 3],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'n_estimators': [300, 400, 500, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_gbm = GridSearchCV(gbm, gbm_param_grid, scoring='neg_mean_squared_error', \n",
    "                                     cv= kf, n_jobs=-1, return_train_score = True, verbose = 1)\n",
    "\n",
    "%time  grid_search_gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'n_estimators': 600}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get the best parameters\n",
    "grid_search_gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbm = grid_search_gbm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): $ 13960.24\n",
      "Mean Squared Error (MSE): 0.015462094678347665\n",
      "Root Mean Square Error (RMSE): 0.12434667136014403\n",
      "Mean Absolute Percent Error (MAPE): 8.7 %.\n"
     ]
    }
   ],
   "source": [
    "#Prediction with tuned hyperparameters\n",
    "grid_gbm_pred = grid_gbm.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(np.expm1(grid_gbm_pred) - np.expm1(y_test))\n",
    "\n",
    "# Print out MAE, MSE, and RMSE\n",
    "print('Mean Absolute Error (MAE): $', round(np.mean(errors), 2))\n",
    "print('Mean Squared Error (MSE):', mean_squared_error(y_test, grid_gbm_pred))\n",
    "print('Root Mean Square Error (RMSE):', np.sqrt(mean_squared_error(y_test, grid_gbm_pred)))\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / np.expm1(y_test))\n",
    "print('Mean Absolute Percent Error (MAPE):', round(np.mean(mape), 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting score: 0.1188 (0.0111)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmse_cv(grid_gbm)\n",
    "print(\"\\nGradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid1={'n_estimators':[1000, 2000, 3000],\n",
    "                'learning_rate':[0.01, 0.05, 0.1],\n",
    "                'max_depth':[2, 3, 4],\n",
    "                'min_samples_leaf':[5, 10, 15],\n",
    "                'min_samples_split': [5, 10],\n",
    "                'loss':['huber']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 38.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_gbm1 = GridSearchCV(gbm, gbm_param_grid1, scoring='neg_mean_squared_error', \n",
    "                                     cv= kf, n_jobs=-1, return_train_score = True, verbose = 1)\n",
    "\n",
    "%time  grid_search_gbm1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-07b26f39cdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search_gbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "# get the best parameters\n",
    "grid_search_gbm1.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbm1 = grid_search_gbm1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with tuned hyperparameters\n",
    "grid_gbm_pred1 = grid_gbm1.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(np.expm1(grid_gbm_pred1) - np.expm1(y_test))\n",
    "\n",
    "# Print out MAE, MSE, and RMSE\n",
    "print('Mean Absolute Error (MAE): $', round(np.mean(errors), 2))\n",
    "print('Mean Squared Error (MSE):', mean_squared_error(y_test, grid_gbm_pred1))\n",
    "print('Root Mean Square Error (RMSE):', np.sqrt(mean_squared_error(y_test, grid_gbm_pred1)))\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / np.expm1(y_test))\n",
    "print('Mean Absolute Percent Error (MAPE):', round(np.mean(mape), 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmse_cv(grid_gbm1)\n",
    "print(\"\\nGradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "# Get numerical feature importances\n",
    "importances_gbm = list(grid_gbm.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_gbm = [(feature, round(importance, 5)) for feature, importance in zip(X_train.columns, importances_gbm)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "gbm_feature_importances = sorted(feature_importances_gbm, key = lambda x: x[1], reverse = True )\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in gbm_feature_importances]\n",
    "\n",
    "gbm_feature_importances_top20 = gbm_feature_importances[:20]\n",
    "featureNames, featureScores = zip(*list(gbm_feature_importances_top20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(len(featureScores)), featureScores, tick_label=featureNames)\n",
    "plt.title('feature importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_gradientboost = grid_gbm.predict(X_train)\n",
    "y_test_gradientboost = grid_gbm.predict(X_test)\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(np.expm1(y_train_gradientboost), np.expm1(y_train), c='black', marker=\"o\", s=15, label = \"Training data\")\n",
    "plt.scatter(np.expm1(y_test_gradientboost), np.expm1(y_test), c='orange', marker='o', s=15, label = \"Validation data\")\n",
    "plt.title(\"Gradient Boosting\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Prices\", fontsize = 16)\n",
    "plt.ylabel(\"Actual Prices\", fontsize = 16)\n",
    "plt.xlim(0, 800000)\n",
    "plt.ylim(0, 800000)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([0, 800000], [0, 800000], c = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params_tuned_model = grid_search_gbm.best_estimator_\n",
    "gbm_feature_importance = 100.0 * (gbm_params_tuned_model.feature_importances_ / gbm_params_tuned_model.feature_importances_.max())\n",
    "gbm_important_features = X_train.columns[gbm_feature_importance >= 1]\n",
    "gbm_unimportant_features = X_train.columns[gbm_feature_importance < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gbmreduced = X_train.drop(gbm_unimportant_features, axis=1)\n",
    "X_test_gbmreduced = X_test.drop(gbm_unimportant_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_feats =GradientBoostingRegressor()\n",
    "\n",
    "gbm_feats.set_params(random_state=42, verbose =1, learning_rate = 0.1, max_depth = 2, min_samples_leaf = 1, n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for multiple hyperparameters:\n",
    "gbm_param_grid_feats={'n_estimators':[100, 500],\n",
    "                      'learning_rate':[0.05, 0.1]\n",
    "                      } \n",
    "grid_search_gbm2 = GridSearchCV(gbm_feats, gbm_param_grid_feats, scoring= 'neg_mean_squared_error',\n",
    "                           cv= kf, n_jobs = 7, return_train_score=True, verbose = 1)\n",
    "grid_search_gbm2.fit(X_train_gbmreduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Gradient Boost's predict method on the test data\n",
    "predictions_tuned_gbm2 = grid_search_gbm2.best_estimator_.predict(X_test_gbmreduced)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(np.expm1(predictions_tuned_gbm2) - np.expm1(y_test))\n",
    "\n",
    "# Print out the mean absolute error (MAE)\n",
    "print('Mean Absolute Error (MAE): $', round(np.mean(errors), 2))\n",
    "print('MSE:', mean_squared_error(y_test, predictions_tuned_gbm2))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, predictions_tuned_gbm2)))\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / np.expm1(y_test))\n",
    "\n",
    "# Calculate and display MAPE\n",
    "#accuracy = 100 - np.mean(mape)\n",
    "print('MAPE:', round(np.mean(mape), 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmse_cv(grid_gbm2)\n",
    "print(\"\\nGradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.2 * grid_gbm1.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
