{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forest Model to Predict House Prices in Ames, Iowa\n",
    "### In this notebook, we are through the basics of using the unsupervised random forest algorithm on the Ames Housing Dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy import stats\n",
    "from math import ceil\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statistics\n",
    "import sklearn.model_selection as ms\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('train6.csv')\n",
    "test = pd.read_csv('test6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning our Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(train.iloc[:,:-1])\n",
    "x = pd.DataFrame(train.iloc[:,1:])\n",
    "x = x.drop(['ylogSalePrice'], axis = 1)\n",
    "y = (train.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size= 0.33, random_state = 66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, x = x):\n",
    "    rmse = np.sqrt(-cross_val_score(model, x_train, y_train, scoring = 'neg_mean_squared_error', cv = kf))\n",
    "    return (rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                      n_jobs=None, oob_score=False, random_state=30, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest = RandomForestRegressor()\n",
    "rforest.set_params(random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=30, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-Squared for both the test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set R^2 is : 0.979981\n",
      "The train set R^2 is : 0.967143\n"
     ]
    }
   ],
   "source": [
    "print('The train set R^2 is : %5f' % rforest.score(x_train, y_train))\n",
    "print('The train set R^2 is : %5f' % rforest.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the prediction \n",
    "rforest_pred = rforest.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Errors\n",
    "Given that we are interested in how far away our average prediction is from the actual value, we take the absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): $ 6915.75\n",
      "Mean Squared Error (MSE): 0.0046791561051761415\n",
      "Root Mean Square Error (RMSE): 0.06840435735518711\n",
      "Root Mean Square Log Error (RMSLE): 0.0054715443822674365\n",
      "Mean Absolute Percent Error (MAPE): 4.37 %.\n",
      "Accuracy: 95.63 %.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def printErrors(Yt, predMod):\n",
    "    \"\"\"\n",
    "    1. Yt = the trained predicted values\n",
    "    2. predMod = the prediction from the fitted model\n",
    "    It thens prints the errors for the model ie MAE, MSE, RMSLE\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = abs(np.expm1(predMod) - np.expm1(Yt))\n",
    "    print('Errors')\n",
    "    print(\"-\" * 50)\n",
    "    print('Mean Absolute Error (MAE): $', round(np.mean(errors), 2))\n",
    "    print(\"-\" * 50)\n",
    "    print('Mean Squared Error (MSE):', mean_squared_error(Yt, predMod))\n",
    "    print(\"-\" * 50)\n",
    "    print('Root Mean Square Error (RMSE):', np.sqrt(mean_squared_error(Yt, predMod)))\n",
    "    print(\"-\" * 50)\n",
    "    print('Root Mean Square Log Error (RMSLE):', np.sqrt(mean_squared_log_error(Yt, predMod)))\n",
    "    print(\"-\" * 50)\n",
    "    mape = 100 * (errors / np.expm1(Yt))\n",
    "    print('Mean Absolute Percent Error (MAPE):', round(np.mean(mape), 2), '%.')\n",
    "    print(\"-\" * 50)\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy')\n",
    "    print(\"-\" * 50)\n",
    "    print('Accuracy:', round( accuracy,2),'%.' )\n",
    "\n",
    "printErrors(y_test, rforest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning : Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid ={'max_depth': [20, 25, 30],\n",
    "             'max_features': ['auto','sqrt','log2'],\n",
    "             'min_samples_split':[2,3,4],\n",
    "             'min_samples_leaf':[1, 3, 5],\n",
    "             'n_estimators': [500, 750, 1000, 1250, 1500]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rforest = ms.GridSearchCV(rforest, param_grid, scoring='neg_mean_squared_error', \n",
    "                                     cv= kf, n_jobs=-1, return_train_score = True)\n",
    "\n",
    "%time grid_search_rforest.fit(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rforest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R - Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The train set R^2 is: %.5f\" % grid_rforest.score(X_train, y_train))\n",
    "print(\"The test set R^2 is is: %.5f\" % grid_rforest.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printErrors(y_test, grid_rforest.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rmse_cv(grid_rforest)\n",
    "print(\"\\nRandom Forest score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rForest = grid_rforest.predict(X_train)\n",
    "y_test_rForest = grid_rforest.predict(X_test)\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(np.expm1(y_train_rForest), np.expm1(y_train), c='black', marker=\"o\", s=15, label = \"Training data\")\n",
    "plt.scatter(np.expm1(y_test_rForest), np.expm1(y_test), c='orange', marker='o', s=15, label = \"Validation data\")\n",
    "plt.title(\"Random Forest\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Prices\", fontsize = 16)\n",
    "plt.ylabel(\"Actual Prices\", fontsize = 16)\n",
    "plt.xlim(0, 800000)\n",
    "plt.ylim(0, 800000)\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.plot([0, 800000], [0, 800000], c = \"grey\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_rf = list(rforest.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feats_rf_score = [(feature, round(importance, 5)) for feature, importance in zip(X_train.columns, feats_rf)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "sorted_feats_rf_score = sorted(feats_rf_score, key = lambda x: x[1], reverse = True )\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in sorted_feats_rf_score]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importances_top20 = sorted_feats_rf_score[:20]\n",
    "featureNames, featureScores = zip(*list(rf_feature_importances_top20))\n",
    "\n",
    "plt.barh(range(len(featureScores)), featureScores, tick_label=featureNames)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('feature importance')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importances')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = 100.0 * (grid_rforest.feature_importances_ / grid_rforest.feature_importances_.max())\n",
    "important_features = X_train.columns[feature_importance >= 0]\n",
    "unimportant_features = X_train.columns[feature_importance < 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train.drop(unimportant_features, axis=1)\n",
    "X_test_reduced = X_test.drop(unimportant_features, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for multiple hyperparameters:\n",
    "rForest_feats = RandomForestRegressor()\n",
    "\n",
    "param_grid ={'max_depth': [10, 20, 30, 40, 50],\n",
    "             'max_features': ['auto','sqrt','log2'],\n",
    "             'min_samples_split':[2,3,4],\n",
    "             'n_estimators': [100, 300, 500, 800]}\n",
    "\n",
    "rForest_feats.set_params(random_state=42)\n",
    "\n",
    "grid_search_rForest2 = GridSearchCV(rForest_feats, param_grid, scoring= 'neg_mean_squared_error',\n",
    "                           cv= kf, n_jobs = -1, return_train_score=True, verbose = 1)\n",
    "grid_search_rForest2.fit(X_train_reduced, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_rForest2.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions_tuned_rForest2 = grid_search_rForest2.best_estimator_.predict(X_test_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printErrors(y_test, predictions_tuned_rForest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rForest = grid_rforest.predict(test)\n",
    "test_predictions_tuned_rForest2 = grid_search_rForest2.best_estimator_.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids = np.arange(1461, 2920, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rForest = np.exp(test_rForest) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({'Id': Ids,'SalePrice': test_rForest})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('predication1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
